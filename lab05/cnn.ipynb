{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "SYIoLxFtn4t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-27T06:01:14.719225Z",
          "iopub.status.busy": "2023-10-27T06:01:14.719007Z",
          "iopub.status.idle": "2023-10-27T06:01:17.352307Z",
          "shell.execute_reply": "2023-10-27T06:01:17.351456Z"
        },
        "id": "iAve6DCL4JH4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-27T06:01:17.356811Z",
          "iopub.status.busy": "2023-10-27T06:01:17.356346Z",
          "iopub.status.idle": "2023-10-27T06:01:23.459377Z",
          "shell.execute_reply": "2023-10-27T06:01:23.458566Z"
        },
        "id": "JWoEqyMuXFF4"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-27T06:01:23.463455Z",
          "iopub.status.busy": "2023-10-27T06:01:23.463206Z",
          "iopub.status.idle": "2023-10-27T06:01:24.113681Z",
          "shell.execute_reply": "2023-10-27T06:01:24.112985Z"
        },
        "id": "K3PAELE2eSU9"
      },
      "outputs": [],
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i])\n",
        "    # The CIFAR labels happen to be arrays,\n",
        "    # which is why you need the extra index\n",
        "    plt.xlabel(class_names[train_labels[i][0]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1 (Provided Model)"
      ],
      "metadata": {
        "id": "X7W0KCoiMm3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Original Model Provided\n",
        "def create_base_model(input_shape=(32, 32, 3), num_classes=len(class_names)):\n",
        "    model = models.Sequential([\n",
        "        # Convolutional layer 1\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        # Convolutional layer 2\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        # Convolutional layer 3\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        # Flattening the output for the dense layer\n",
        "        layers.Flatten(),\n",
        "        # Dense layer\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        # Output layer\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "_lWhudS0LYsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and compile the base model\n",
        "model1 = create_base_model()\n",
        "model1.compile(optimizer='adam',\n",
        "                   loss='sparse_categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "# Model summary\n",
        "model1.summary()\n",
        "\n",
        "history1 = model1.fit(train_images, train_labels, epochs=10,\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "id": "vtK57zBZMYNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history1.history['accuracy'], label='accuracy')\n",
        "plt.plot(history1.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model1.evaluate(test_images,  test_labels, verbose=2)"
      ],
      "metadata": {
        "id": "OygA_IG7NTLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'test_loss: {test_loss}, test_accuracy: {test_acc}')"
      ],
      "metadata": {
        "id": "ejMioYK2NXtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2 (Modified base on Provided Model)"
      ],
      "metadata": {
        "id": "2jQflmxdMp9Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-27T06:01:26.619840Z",
          "iopub.status.busy": "2023-10-27T06:01:26.619256Z",
          "iopub.status.idle": "2023-10-27T06:02:36.728327Z",
          "shell.execute_reply": "2023-10-27T06:02:36.727472Z"
        },
        "id": "MdDzI75PUXrG"
      },
      "outputs": [],
      "source": [
        "# A modified model base on the provided model\n",
        "def create_base_modified_model(input_shape=(32, 32, 3), num_classes=len(class_names)):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.2),\n",
        "\n",
        "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and compile the base model\n",
        "model2 = create_base_modified_model()\n",
        "model2.compile(optimizer='adam',\n",
        "                   loss='sparse_categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "# Model summary\n",
        "model2.summary()\n",
        "\n",
        "history2 = model2.fit(train_images, train_labels, epochs=10,\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "id": "3iVshGAxMvj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history2.history['accuracy'], label='accuracy')\n",
        "plt.plot(history2.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model2.evaluate(test_images,  test_labels, verbose=2)"
      ],
      "metadata": {
        "id": "xqI4tWJuNhHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'test_loss: {test_loss}, test_accuracy: {test_acc}')"
      ],
      "metadata": {
        "id": "WYGGeY3RNk0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 3 (Transfer Learning)"
      ],
      "metadata": {
        "id": "Pktta6Mfm1WL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vgg16_model(input_shape=(32, 32, 3), num_classes=len(class_names)):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    # Resize images to 224x224 within the model\n",
        "    resized_inputs = tf.image.resize(inputs, (224, 224))\n",
        "\n",
        "    # Preprocess the inputs as per VGG16's requirements\n",
        "    x = preprocess_input(resized_inputs)\n",
        "\n",
        "    # Load the VGG16 base model, excluding its top fully connected layers\n",
        "    base_model = VGG16(include_top=False, weights='imagenet', input_tensor=x)\n",
        "\n",
        "    # Freeze the layers of the base model to prevent them from being updated during training\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Extend the base model for multi-class classification\n",
        "    x = layers.Flatten()(base_model.output)  # Flatten the output of the base model\n",
        "    x = layers.Dense(512, activation='relu')(x)  # Add a fully connected layer\n",
        "    x = layers.Dropout(0.5)(x)  # Incorporate dropout for regularization\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)  # Final layer for multi-class classification\n",
        "\n",
        "    # Construct the new model\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "kf-ZbZMwm3Y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and compile the base model\n",
        "model3 = create_vgg16_model()\n",
        "model3.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Model summary\n",
        "model3.summary()\n",
        "\n",
        "history3 = model3.fit(train_images, train_labels, epochs=10,\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "id": "iY_pVFRZm8dN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history3.history['accuracy'], label='accuracy')\n",
        "plt.plot(history3.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model3.evaluate(test_images,  test_labels, verbose=2)"
      ],
      "metadata": {
        "id": "1GUCDFYGnsEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'test_loss: {test_loss}, test_accuracy: {test_acc}')"
      ],
      "metadata": {
        "id": "dxtTPhKAnvyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKgyC5K_4O0d"
      },
      "source": [
        "### Prediction the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess an image\n",
        "def load_and_preprocess_image(url, target_size=(32, 32)):\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "    img = img.resize(target_size)\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img /= 255.0\n",
        "    return img\n",
        "\n",
        "models = [model1, model2, model3]\n",
        "def predict(model):\n",
        "  predictions = model.predict(img)\n",
        "  predicted_class = class_names[np.argmax(predictions[0])]\n",
        "  print(f\"Image URL: {url}\")\n",
        "  print(f\"Predicted class: {predicted_class}\\n\")\n",
        "\n",
        "# URLs of the images\n",
        "image_urls = [\n",
        "    \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT0KnNu46povUcwKNf8fGiljnFfnD20nwYHd1r44JUikA&s\",\n",
        "    \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSu-2Z3an9txHQSExt053UQzZEHkW_G0HZoXy_k1uQL2A&s\",\n",
        "    \"https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcSO7S6Lztyh63gN6oo1GESyOAfBwFYNkcGKBkrJlAgfkAm8Wa6PaQrQs233QFxBYzYn3Jy6g1AT5wwNl1X789grdblM_3JpruTLerJ5CA\",\n",
        "    \"https://media.wired.com/photos/590951f9d8c8646f38eef333/4:3/w_929,h_697,c_limit/walmart-advanced-vehicle-experience-wave-concept-truck.jpg\",\n",
        "    \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR49UeOkEvtCskTbXc5OQ4UTs3wTcaRUnRNjFO32FROCg&s\",\n",
        "    \"https://i.natgeofe.com/k/520e971d-7a22-4a6f-90dc-258df74e45bc/american-goldfinch.jpg\"\n",
        "]\n",
        "\n",
        "# Load, preprocess, and predict each image\n",
        "for url in image_urls:\n",
        "    img = load_and_preprocess_image(url)\n",
        "    for i, m in enumerate(models):\n",
        "      print(f'Model: {i+1}')\n",
        "      predict(m)\n"
      ],
      "metadata": {
        "id": "FYCHSW-XGCfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess an image\n",
        "def load_and_preprocess_image(url, target_size=(32, 32)):\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "    img = img.resize(target_size)\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img /= 255.0\n",
        "    return img\n",
        "\n",
        "def predict_and_show(model, img, url):\n",
        "    predictions = model.predict(img)\n",
        "    predicted_class = class_names[np.argmax(predictions[0])]\n",
        "    plt.imshow(img[0])\n",
        "    plt.title(f\"Predicted class: {predicted_class}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    print(f\"Image URL: {url}\")\n",
        "    print(f\"Predicted class: {predicted_class}\\n\")\n",
        "\n",
        "models = [model1, model2, model3]\n",
        "\n",
        "# URLs of the images\n",
        "image_urls = [\n",
        "    \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT0KnNu46povUcwKNf8fGiljnFfnD20nwYHd1r44JUikA&s\",\n",
        "    \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSu-2Z3an9txHQSExt053UQzZEHkW_G0HZoXy_k1uQL2A&s\",\n",
        "    \"https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcSO7S6Lztyh63gN6oo1GESyOAfBwFYNkcGKBkrJlAgfkAm8Wa6PaQrQs233QFxBYzYn3Jy6g1AT5wwNl1X789grdblM_3JpruTLerJ5CA\",\n",
        "    \"https://media.wired.com/photos/590951f9d8c8646f38eef333/4:3/w_929,h_697,c_limit/walmart-advanced-vehicle-experience-wave-concept-truck.jpg\",\n",
        "    \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR49UeOkEvtCskTbXc5OQ4UTs3wTcaRUnRNjFO32FROCg&s\",\n",
        "    \"https://i.natgeofe.com/k/520e971d-7a22-4a6f-90dc-258df74e45bc/american-goldfinch.jpg\"\n",
        "]\n",
        "\n",
        "# Load, preprocess, and predict each image\n",
        "for url in image_urls:\n",
        "    img = load_and_preprocess_image(url)\n",
        "    for i, m in enumerate(models):\n",
        "      print(f'Model: {i+1}')\n",
        "      predict_and_show(m, img, url)\n"
      ],
      "metadata": {
        "id": "IpAuHYfhQ6Bq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}